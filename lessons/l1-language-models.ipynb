{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 Language Models, Chat format and Tokes\n",
    "Date 27-11-2023\n",
    "## Setup\n",
    "### Load an API key and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "_ = load_dotenv('/home/janvandenbrand/repos/dlai-building-systems-with-chatgpt/.env')\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ['OPENAI_API_KEY']    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "This function will make it easure to use prompt and look at the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0 \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt the model and get a completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"take the letters in lollipop and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way tokens are generated influences the reponse. The more common a combination of letters, the bigger the token. Generally tokens are about 4 characters long or about 3/4 of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"take the letters in l-o-l-l-i-p-o-p and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model='gpt-3.5-turbo', temperature=0, max_tokens=500):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPT's prompt are engineered at three levels:\n",
    "* system - sets the general tone of the assistant \n",
    "* assistant - generates the LLM response\n",
    "* user - prompts the assistant to create a response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, happy carrot, orange and bright,\n",
      "Growing tall with all your might.\n",
      "In the garden you shine so cheery,\n",
      "Making everyone oh so merry.\n",
      "\n",
      "With a leafy green, you wave hello,\n",
      "Beneath the soil, you gently grow.\n",
      "Your sweetness inside, oh so grand,\n",
      "A healthy snack in every hand.\n",
      "\n",
      "From the ground, you pop up high,\n",
      "Reaching for the sunny sky.\n",
      "Your crunchy taste, a pure delight,\n",
      "You make our tastebuds take flight.\n",
      "\n",
      "Oh, happy carrot, you bring us glee,\n",
      "A vibrant veggie, full of glee.\n",
      "Juicy and delicious, you are a treat,\n",
      "A cheery carrot oh so sweet!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a sunny garden, a happy carrot grew surrounded by friendly vegetables who giggled and danced in the breeze.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system',\n",
    "     'content': 'All your response must be one sentence long'},\n",
    "     {'role': 'user',\n",
    "     'content': 'write me a story about the happy carrot'}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a veggie patch so neat, lived a happy carrot with a smile so sweet.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'you are an assistent who responds in the style of Dr Seuss. All your responses must be one sentence long.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'write me a story about a happy carrot.'\n",
    "    }\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The openai >= 1.0.0 requires a different specification of chat completion object. See https://platform.openai.com/docs/api-reference/chat/object  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages,\n",
    "                                   model='gpt-3.5-turbo',\n",
    "                                   temperature=0,\n",
    "                                   max_tokens=500):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    token_dict = {\n",
    "        'prompt_tokens':response.usage.prompt_tokens,\n",
    "        'completion_tokens':response.usage.completion_tokens,\n",
    "        'total_tokens':response.usage.total_tokens\n",
    "    }\n",
    "    return content, token_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':'you are an assistant who responds in the style of Dr Seuss.'\n",
    "    },\n",
    "    { \n",
    "        'role':'user',\n",
    "        'content':'write me a very short poem about a happy carrot.'\n",
    "    }\n",
    "]\n",
    "response, token_dict = get_completion_and_token_count(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "With a smile that's wide, and a leafy fringe.\n",
      "It grows in the garden, under the sun,\n",
      "Bringing joy and laughter, oh what fun!\n",
      "\n",
      "With a crunch and a munch, it's a tasty treat,\n",
      "Full of vitamins and nutrients, oh so sweet.\n",
      "From the ground it springs, with a cheerful hop,\n",
      "A happy carrot, never wanting to stop.\n",
      "\n",
      "So let's celebrate this veggie delight,\n",
      "With a song and a dance, all through the night.\n",
      "For the happy carrot, so full of glee,\n",
      "Brings happiness to you and me!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 36, 'completion_tokens': 127, 'total_tokens': 163}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
